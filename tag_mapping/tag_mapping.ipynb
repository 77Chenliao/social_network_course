{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append('..')\n",
    "import config\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from opencc import OpenCC\n",
    "\n",
    "# 初始化转换器，t2s表示从繁体转简体\n",
    "cc = OpenCC('t2s')\n",
    "\n",
    "data_path_prefix = config.data_path\n",
    "vector_db_path = config.vector_db_path\n",
    "os.environ[\"OPENAI_API_KEY\"] = config.api_key\n",
    "os.environ[\"OPENAI_API_BASE\"] = config.api_base\n",
    "model_name = config.model\n",
    "# model_name = 'gpt-4'\n",
    "retrive_top_k = config.top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = OpenAIEmbeddings(\n",
    "    openai_api_base=os.environ[\"OPENAI_API_BASE\"],\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    request_timeout=60,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(system_message=None, human_message=None, model_name=model_name):\n",
    "    answer = ''\n",
    "    api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    api_base = os.environ[\"OPENAI_API_BASE\"]\n",
    "    message=[{\"role\":\"system\",\"content\":system_message},{\"role\":\"user\",\"content\":human_message}]\n",
    "    client = ChatOpenAI(\n",
    "        openai_api_key=api_key,\n",
    "        openai_api_base=api_base,\n",
    "        model=model_name,\n",
    "        temperature=0.2,\n",
    "    )\n",
    "    answer = client.invoke(message).content.strip()\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b868d59df44e41ed886cc4ed8357b3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/275717 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 读取tag.txt文件\n",
    "tags_data = pd.read_csv(os.path.join(data_path_prefix, 'tag.txt'), sep='\\t', header=None, names=['user_id', 'tags'])\n",
    "# 提取所有的标签，并统计每个标签的出现次数\n",
    "tag_counts = dict()\n",
    "all_tags = tags_data['tags'].dropna().str.split('_')\n",
    "for tag in tqdm(all_tags):\n",
    "    for t in tag:\n",
    "        simplified_text = cc.convert(t)\n",
    "        tag_counts[simplified_text] = tag_counts.get(simplified_text, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将标签出现次数转化为数据框\n",
    "tag_count_distribution = pd.DataFrame.from_dict(tag_counts, orient='index', columns=['count']).sort_values('count', ascending=False)\n",
    "\n",
    "# 重要类别\n",
    "k = 500\n",
    "main_tags = tag_count_distribution[:k]\n",
    "# 长尾类别（注意此处因为目前是测试阶段，因此限制了出现次数的上下限，正式运行时，此处可以改为>5。>5的数据共有16000条左右，还在可以接受的范围里。另，全量共有28w条左右的标签，不可能全量运行）\n",
    "long_tail_tags = tag_count_distribution[(tag_count_distribution['count']>20) & (tag_count_distribution['count']<26)][k:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorstore_from_kg(data=None, output_path: str = None, embed_model=embed_model, save=True\n",
    "):\n",
    "    if data is None:\n",
    "        data = []\n",
    "    if not os.path.exists(output_path):\n",
    "        feature = data\n",
    "        vectorstore = FAISS.from_texts(texts=feature, embedding=embed_model)\n",
    "        if save:\n",
    "            vectorstore.save_local(output_path)\n",
    "    else:\n",
    "        vectorstore = FAISS.load_local(output_path, embed_model, allow_dangerous_deserialization=True)\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对重要标签进行处理，对齐其中语义相近的标签\n",
    "tag_des = []\n",
    "split_flag = '，该标签的描述为：'\n",
    "if os.path.exists(os.path.join(data_path_prefix, \"main_tags.csv\")):\n",
    "    df = pd.read_csv(os.path.join(data_path_prefix, \"main_tags.csv\"))\n",
    "    # 读取向量数据库\n",
    "    vector_db = vectorstore_from_kg(output_path=vector_db_path)\n",
    "else:\n",
    "    # 将标签逐个进行描述，增加额外的信息，使得嵌入向量更加合理\n",
    "    for tag in tqdm(main_tags.index):\n",
    "        system_messgae = \"你是一个对用户兴趣标签十分了解的专家，请在50个字以内描述一下输入给你的用户兴趣标签。请注意，输入的词语并不是单纯的词，而是一个用户的兴趣，你需要做的是阐述当这个词被当作用户画像的一部分时，它的含义是什么。\"\n",
    "        human_message = tag\n",
    "        answer = chat(system_messgae, human_message)\n",
    "        tag_des.append(answer)\n",
    "    main_tags[\"tag_des\"] = tag_des\n",
    "\n",
    "    # 把标签及其描述处理成如[音乐，该标签的描述为XXX]的形式\n",
    "    data = list(\n",
    "        main_tags.reset_index(drop=False).apply(\n",
    "            lambda x: x[0] + split_flag + x[\"tag_des\"], axis=1\n",
    "        )\n",
    "    )\n",
    "    # 创建临时向量数据库\n",
    "    vector_db_temp = vectorstore_from_kg(data, vector_db_path, save=False)\n",
    "\n",
    "    # 对重要标签中的每个标签，都从向量数据库中检索top2的标签，其中第一个为该标签本身，第二个为与其相似的标签\n",
    "    data_list = []\n",
    "    for i in tqdm(data):\n",
    "        retrieve = [\n",
    "            (j.page_content, s)\n",
    "            for j, s in vector_db_temp.similarity_search_with_relevance_scores(i, 2)\n",
    "        ]\n",
    "        data = [\n",
    "            retrieve[0][0],  # tag1\n",
    "            tag_count_distribution.loc[retrieve[0][0].split(split_flag)[0]][\n",
    "                \"count\"\n",
    "            ],  # tag1_count\n",
    "            retrieve[1][0],  # tag2\n",
    "            tag_count_distribution.loc[retrieve[1][0].split(split_flag)[0]][\n",
    "                \"count\"\n",
    "            ],  # tag2_count\n",
    "            retrieve[0][1]\n",
    "            - retrieve[1][1],  # tag1与tag2检索分数的差值，用于衡量两个标签有多相近\n",
    "        ]\n",
    "        data_list.append(data)\n",
    "    df = pd.DataFrame(\n",
    "        data_list,\n",
    "        columns=[\"tag1\", \"tag1_count\", \"tag2\", \"tag2_count\", \"relevance_score_diff\"],\n",
    "    )\n",
    "\n",
    "    # 将相近的标签进行对齐，生成最终的tag\n",
    "    df[\"final_tag\"] = df.apply(\n",
    "        lambda x: (\n",
    "            x[\"tag1\"]\n",
    "            if x[\"relevance_score_diff\"]\n",
    "            >= 0.1  # 差值大于0.1的不考虑合并，经观察，没有合并的必要\n",
    "            or (\n",
    "                len(x[\"tag1\"].split(split_flag)[0])\n",
    "                == len(x[\"tag2\"].split(split_flag)[0])\n",
    "                and x[\"tag1_count\"] >= x[\"tag2_count\"]\n",
    "            )\n",
    "            or len(x[\"tag1\"].split(split_flag)[0])\n",
    "            < len(\n",
    "                x[\"tag2\"].split(split_flag)[0]\n",
    "            )  # 考虑标签的长度，希望最终的标签尽可能短，过长的标签有较大可能是如“偶稀饭睡觉觉”这类描述性标签，转化为“爱睡觉”是比较合理的。另外，当标签长度一致的时候，使用出现次数进行进一步的判断。\n",
    "            else x[\"tag2\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    \n",
    "    # 把标签及其描述处理成如[音乐，该标签的描述为XXX]的形式\n",
    "    data = list(df['final_tag'].drop_duplicates())\n",
    "    # 创建向量数据库\n",
    "    vector_db = vectorstore_from_kg(data, vector_db_path, save=True)\n",
    "    \n",
    "    df.to_csv(os.path.join(data_path_prefix, \"main_tags.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66063eeac0ca48a7bdeb6155d5d8a1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/382 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_list = []\n",
    "data_temp = pd.read_csv(os.path.join(data_path_prefix, 'processed_tags.csv'), header=None)\n",
    "check_point = len(data_temp)\n",
    "long_tail_tags_list= long_tail_tags.index.tolist()[check_point:]\n",
    "for i, tag in tqdm(enumerate(long_tail_tags_list), total=len(long_tail_tags_list)):\n",
    "    # 为每个tag生成一段描述\n",
    "    system_messgae = \"你是一个对用户兴趣标签十分了解的专家，请在50个字以内描述一下输入给你的用户兴趣标签。请注意，输入的词语并不是单纯的词，而是一个用户的兴趣，你需要做的是阐述当这个词被当作用户画像的一部分时，它的含义是什么。\"\n",
    "    human_message = tag\n",
    "    answer = chat(system_messgae, human_message)\n",
    "    tag_with_desc = tag + split_flag + answer\n",
    "    # 利用标签及其描述进行检索\n",
    "    retrieve_tags = [(i.page_content.split(split_flag)[0]) for i, _ in vector_db.similarity_search_with_relevance_scores(tag_with_desc, retrive_top_k)]\n",
    "    \n",
    "    # 读取分组的prompt\n",
    "    with open('./prompt.txt', 'r') as f:\n",
    "        prompt = f.read()\n",
    "    # 进行标签分组\n",
    "    system_messgae = '你是一个标签分组的标注员，请协助用户从候选标签组中选择出一个与输入标签最匹配的标签组，若用户提供的候选列表中没有合适的标签组，请返回None'\n",
    "    human_message = prompt.replace('<<<tag>>>', tag_with_desc).replace('<<<candidates>>>', ','.join(retrieve_tags))\n",
    "    answer = chat(system_messgae, human_message)\n",
    "    data_for_tag = [i+check_point, tag, answer, retrieve_tags, tag_with_desc]\n",
    "    data_list.append(data_for_tag)\n",
    "    # 将结果持续追加至本地\n",
    "    with open(os.path.join(data_path_prefix, 'processed_tags.csv'), 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(data_for_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "social_network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
